---
title: "Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning"
collection: publications
permalink: https://arxiv.org/abs/2509.00975
excerpt: "ReaL-TG fine-tunes language models with RL to perform explainable link forecasting on temporal graphs, producing validated reasoning chains."
date: 2025-09-05
venue: 'arXiv'
slidesurl: 'https://arxiv.org/abs/2509.00975'
paperurl: 'https://arxiv.org/pdf/2509.00975'
citation: 'Z Ding, S Huang, Z Cao, E Kondrup, Z Yang, X Huang, Y Sui, Z Yuan, Y Zhu, X Hu, Y He, F Poursafaei, M Bronstein, A Vlachos, Self-Exploring LMs for Explainable Link Forecasting on Temporal Graphs via RL, arXiv:2509.00975, 2025'
authors:
  - "Zifeng Ding"
  - "Shenyang Huang"
  - "Zeyu Cao"
  - "Emma Kondrup"
  - "Zachary Yang"
  - "Xingyue Huang"
  - "Yuan Sui"
  - "Zhangdie Yuan"
  - "Yuqicheng Zhu"
  - "Xianglong Hu"
  - "Yuan He"
  - "Farimah Poursafaei"
  - "Michael Bronstein"
  - "Andreas Vlachos"
categories:
  - "Machine Learning"
tags:
  - "Temporal Graphs"
  - "Reinforcement Learning"
---

ReaL-TG is a reinforcement learning framework that fine-tunes language models for explainable link forecasting on temporal graphs. It encourages models to develop reasoning strategies by exploring graph structures and learning to generate high-quality explanations. Using a multi-task, multi-objective reward design, ReaL-TG optimizes both forecasting accuracy and explanation quality, where the latter is assessed via automatic graph-based verification and model-based judges. Our framework yields strong forecasting performance and outperforms instruction-tuned LLMs in explanation quality while maintaining comparably high faithfulness. Human evaluations on the HiEve dataset further confirm the superiority of ReaL-TG in producing clear, coherent, and insightful explanations, with moderate faithfulness.


